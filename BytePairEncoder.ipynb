{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4825037c-7dc7-48c7-b5df-44e51add9fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('shakespeare.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5c4096b9-bd5f-418a-ae74-8f03e77c3e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BytePairEncoder():\n",
    "    def __init__(self,vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.merges = {}\n",
    "        self.vocab = {}\n",
    "    \n",
    "    def _build_vocab(self):\n",
    "        self.vocab = {i:bytes([i]) for i in range(256)}\n",
    "        for (x,y),idx in self.merges.items():\n",
    "            self.vocab[idx] = self.vocab[x] + self.vocab[y]\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        vocab = {k:v.decode('utf-8',errors='replace') for k,v in self.vocab.items()}\n",
    "        return vocab\n",
    "    \n",
    "    def ids_to_token(self,ids):\n",
    "        tokens = []\n",
    "        for idx in ids:\n",
    "            tokens.append(self.vocab[idx].decode('utf-8',errors='replace'))\n",
    "        return tokens\n",
    "    def get_pair_counts(self,tokens):\n",
    "        counts = {}\n",
    "        for x,y in zip(tokens,tokens[1:]):\n",
    "            counts[(x,y)] = counts.get((x,y),0) + 1\n",
    "        return counts\n",
    "    def fit(self,text):\n",
    "        self.merges = {}\n",
    "        self.vocab = {}\n",
    "        tokens = list(map(int,text.encode('utf-8')))\n",
    "        ids = list(tokens)\n",
    "        for i in range(self.vocab_size - 255):\n",
    "            tokens = self.get_pair_counts(ids)\n",
    "            pair = max(tokens,key=tokens.get)\n",
    "            idx = 256 + i\n",
    "            self.merges[pair] = idx\n",
    "            enc = []\n",
    "            i=0\n",
    "            while i <len(ids):\n",
    "                if i < len(ids)-1 and (ids[i] == pair[0] and ids[i+1] == pair[1]):\n",
    "                    enc.append(idx)\n",
    "                    i+=2\n",
    "                else:\n",
    "                    enc.append(ids[i])\n",
    "                    i+=1\n",
    "            idx+=1\n",
    "            ids = enc\n",
    "    def encode(self, x):\n",
    "        x_bytes = x.encode('utf-8')\n",
    "        ids = list(x_bytes)\n",
    "\n",
    "        while len(ids) >= 2:\n",
    "            pair_counts = self.get_pair_counts(ids)\n",
    "            pair = min(pair_counts, key=lambda p: self.merges.get(p, float(\"inf\")))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "            enc = []\n",
    "            idx = self.merges[pair]\n",
    "            i = 0\n",
    "            while i < len(ids):\n",
    "                if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "                    enc.append(idx)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    enc.append(ids[i])\n",
    "                    i += 1\n",
    "            ids = enc\n",
    "        return ids\n",
    "\n",
    "    \n",
    "    def decode(self,ids):\n",
    "        if not self.vocab:\n",
    "            self._build_vocab()\n",
    "        tokens = b\"\".join([self.vocab[i] for i in ids])\n",
    "        return tokens.decode('utf-8',errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b06a32b7-34d0-45b7-94f3-0b2032bb7090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc = BytePairEncoder(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f9e24d92-aaa2-4a48-b911-80bb62417b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "19628797-6b12-40e9-ae57-8e30b08adaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = enc.encode(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6112ed2f-664a-43db-ac68-28e9152402ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thy self thy foe, to thy sweet self too cruel:\n",
      "Thou that art now the world's fresh ornament,\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content,\n",
      "And tender churl mak'st waste in niggarding:\n",
      "Pity the world, or else this glutton be,\n",
      "To eat the world's due, by the grave and thee.\n",
      "\n",
      "When forty winters shall besiege thy brow,\n",
      "And dig deep trenches in thy beauty's field,\n",
      "Thy youth's proud livery so gazed on now,\n",
      "Will be a tattered weed of small worth held:  \n",
      "Then being asked, where all thy beauty lies,\n",
      "Where all the treasure of thy lusty days;\n",
      "To say within thine own deep sunken eyes,\n",
      "Were an all-eating shame, and thriftless prais\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c4ba805c-7fbb-4cd9-a3c1-05c84a778b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-H-E- -S-O-N-N-E-T-S-\n",
      "\n",
      "-by -W-ill-i-am- -S-ha-k-es-p-ear-e-\n",
      "\n",
      "-From- fa-ir-est -c-rea-tur-es -w-e -des-ir-e -inc-reas-e,\n",
      "That -there-by -beauty's -r-ose -m-ight -ne-ver- d-i-e,\n",
      "But -as -the -ri-per- should -by -time -dec-eas-e,\n",
      "-H-is -tend-er- h-e-ir- m-ight -bear- his -m-e-mor-y-:\n",
      "-But -thou -cont-rac-ted -to- th-ine own- b-right -eyes-,\n",
      "-F-eed-'st -thy -light-'s -f-la-me -with- s-elf---sub-st-an-ti-al- f-u-el-,\n",
      "-M-ak-ing a- f-am-ine -where -ab-und-ance -li-es-,\n",
      "Th-y -self- thy -fo-e, -to- thy -sweet -self -too -c-ru-el-:\n",
      "-Thou- that -art -now- the -wor-ld-'s -f-res-h- -orn-am-ent-,\n",
      "And -on-ly -her-a-ld -to the -g-a-ud-y -s-pr-ing-,\n",
      "W-ith-in th-ine own- b-u-d -b-uri-est -thy -cont-ent-,\n",
      "And -tend-er -ch-ur-l- m-ak-'st -w-ast-e -in -n-ig-g-ar-d-ing-:\n",
      "-P-it-y -the -wor-ld-, -or -el-s-e th-is -gl-ut-t-on- b-e,\n",
      "-To -ea-t -the -wor-ld-'s -d-u-e, -by -the -gra-ve -and -th-ee-.\n",
      "\n",
      "-Wh-en- for-ty -w-inter-s -sha-ll- b-es-i-e-g-e thy -b-row-,\n",
      "And -di-g- d-eep- -tr-en-ch-es -in thy -beauty's -fi-el-d-,\n",
      "Th-y -you-th-'s -proud -li-ver-y -so -g-a-z-ed -on -now-,\n",
      "W-ill- be -a -t-at-ter-ed -w-e-ed -of s-m-all- wor-th -h-el-d-:  \n",
      "-Th-en- be-ing a-s-k-ed, -where -all- thy -beauty -li-es-,\n",
      "Wh-ere -all- the -tr-eas-ure -of thy -l-u-st-y -day-s-;\n",
      "-To -s-ay -with-in th-ine own- d-eep- s-un-k-en -eyes-,\n",
      "W-ere -an- all---ea-ting- sha-m-e, and -th-ri-f-t-less -prais\n"
     ]
    }
   ],
   "source": [
    "print('-'.join(enc.ids_to_token(ids)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
